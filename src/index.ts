/**
 * ============================================================================
 * OPENAI-TO-CLOUDFLARE AI PROXY - MAIN ENTRY POINT
 * ============================================================================
 *
 * This service acts as an HTTP proxy that makes Cloudflare Workers AI appear
 * as OpenAI-compatible. It translates OpenAI API requests into Cloudflare
 * Workers AI format and translates responses back to OpenAI format.
 *
 * @version 1.9.30
 * @see https://github.com/your-repo/SPECIFICATION.md
 *
 * ============================================================================
 * ARCHITECTURE
 * ============================================================================
 *
 * This main entry point is intentionally minimal - it only handles:
 * 1. Request routing
 * 2. Authentication (via middleware)
 * 3. Error handling
 * 4. Performance logging
 *
 * All business logic is delegated to specialized handlers:
 * - handlers/chat.handler.ts       â†’ Chat Completions API
 * - handlers/responses.handler.ts  â†’ Responses API
 * - handlers/embeddings.handler.ts â†’ Embeddings API
 * - handlers/image.handler.ts      â†’ Image Generation API
 * - handlers/models.handler.ts     â†’ Models listing
 * - handlers/health.handler.ts     â†’ Health checks
 * - handlers/assistants.handler.ts â†’ Assistants API (stub)
 * - handlers/threads.handler.ts    â†’ Threads API (stub)
 *
 * Authentication is handled by:
 * - middleware/auth.middleware.ts  â†’ Bearer token validation
 *
 * ============================================================================
 * SUPPORTED ENDPOINTS
 * ============================================================================
 *
 * âœ… POST /v1/chat/completions    - Chat completions (streaming/non-streaming)
 * âœ… POST /v1/responses           - OpenAI Responses API format
 * âœ… POST /v1/embeddings          - Text embeddings generation
 * âœ… POST /v1/images/generations  - Image generation (DALL-E â†’ Flux)
 * âœ… GET  /v1/models              - List available models
 * âœ… GET  /health                 - Health check (no auth required)
 * âœ… GET  /models/search          - Model info page (debug)
 * ðŸ”„ POST /v1/assistants/*        - Assistants API (501 stub)
 * ðŸ”„ POST /v1/threads/*           - Threads API (501 stub)
 *
 * ============================================================================
 * KEY FEATURES
 * ============================================================================
 *
 * âœ… Full OpenAI API compatibility
 * âœ… Model aliasing (gpt-4 â†’ Qwen, dall-e-3 â†’ Flux, etc.)
 * âœ… Tool calling support (function calling)
 * âœ… Streaming responses (SSE format)
 * âœ… Reasoning models support (o1, o3 series)
 * âœ… Request validation and normalization
 * âœ… Bearer token authentication
 * âœ… Comprehensive error handling
 * âœ… Performance logging
 *
 * ============================================================================
 */

// ============================================================================
// IMPORTS
// ============================================================================

// API Handlers
import { handleHealth } from './handlers/health.handler';
import { handleListModels } from './handlers/models.handler';
import { handleEmbeddings } from './handlers/embeddings.handler';
import { handleImageGeneration } from './handlers/image.handler';
import { handleAssistants } from './handlers/assistants.handler';
import { handleThreads } from './handlers/threads.handler';
import { handleResponses } from './handlers/responses.handler';
import { handleChatCompletions } from './handlers/chat.handler';

// Middleware
import { authenticateRequest, requiresAuth } from './middleware/auth.middleware';

// Utilities
import { PROXY_VERSION } from './constants';
import { errorResponse, notFoundError } from './errors';
import { displayModelsInfo } from './model-helpers';
import type { Env } from './types';

// ============================================================================
// WORKER EXPORT
// ============================================================================

/**
 * Cloudflare Workers entry point.
 * Handles all incoming HTTP requests and routes them to appropriate handlers.
 */
export default {
  /**
   * Main request handler.
   *
   * @param request - Incoming HTTP request
   * @param env - Cloudflare Workers environment bindings
   * @returns HTTP response
   */
  async fetch(request: Request, env: Env): Promise<Response> {
    const url = new URL(request.url);
    const startTime = Date.now();

    // Log incoming request
    console.log(
      `[${new Date().toISOString()}] [v${PROXY_VERSION}] ` +
      `${request.method} ${url.pathname}`
    );

    // ========================================================================
    // HEALTH CHECK (No Auth Required)
    // ========================================================================

    if (url.pathname === '/health' && request.method === 'GET') {
      return handleHealth(env);
    }

    // ========================================================================
    // AUTHENTICATION
    // ========================================================================

    // Check if endpoint requires authentication
    if (requiresAuth(url.pathname)) {
      const authResult = authenticateRequest(request, env, url.pathname);
      if (!authResult.success) {
        return authResult.error!;
      }
    }

    // ========================================================================
    // REQUEST ROUTING
    // ========================================================================

    try {
      let response: Response;

      // Route based on pathname and method
      switch (true) {
        // ----------------------------------------------------------------
        // Debug/Info Endpoints
        // ----------------------------------------------------------------

        case url.pathname === '/models/search' && request.method === 'GET':
          response = await displayModelsInfo(env, request);
          break;

        // ----------------------------------------------------------------
        // OpenAI API Endpoints
        // ----------------------------------------------------------------

        case url.pathname === '/v1/models' && request.method === 'GET':
          response = await handleListModels(env);
          break;

        case url.pathname === '/v1/chat/completions' && request.method === 'POST':
          response = await handleChatCompletions(request, env);
          break;

        case url.pathname === '/v1/responses' && request.method === 'POST':
          response = await handleResponses(request, env);
          break;

        case url.pathname === '/v1/images/generations' && request.method === 'POST':
          response = await handleImageGeneration(request, env);
          break;

        case url.pathname === '/v1/embeddings' && request.method === 'POST':
          response = await handleEmbeddings(request, env);
          break;

        // ----------------------------------------------------------------
        // Assistants & Threads API (Stubs)
        // ----------------------------------------------------------------

        case url.pathname.startsWith('/v1/assistants'):
          response = await handleAssistants(request, env, url);
          break;

        case url.pathname.startsWith('/v1/threads'):
          response = await handleThreads(request, env, url);
          break;

        // ----------------------------------------------------------------
        // 404 - Not Found
        // ----------------------------------------------------------------

        default:
          response = notFoundError();
      }

      // ====================================================================
      // RESPONSE LOGGING
      // ====================================================================

      const latency = Date.now() - startTime;
      console.log(
        `[${new Date().toISOString()}] ${url.pathname} ` +
        `completed in ${latency}ms`
      );

      return response;

    } catch (error) {
      // ====================================================================
      // ERROR HANDLING
      // ====================================================================

      const latency = Date.now() - startTime;
      console.error(
        `[${new Date().toISOString()}] Unhandled error after ${latency}ms:`,
        error
      );

      return errorResponse(
        "Internal server error",
        500,
        "api_error",
        error instanceof Error ? error.message : 'Unknown error'
      );
    }
  }
};
